{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5f624f",
   "metadata": {},
   "source": [
    "## Pyspark Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b1b35",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab381291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4d1c1",
   "metadata": {},
   "source": [
    "Set connection type and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddcb62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/24 18:59:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea60384",
   "metadata": {},
   "source": [
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fa70a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-24 18:07:17--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-01.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.114.4\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/035746e8-4e24-47e8-a3ce-edcf6d1b11c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230224%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230224T180718Z&X-Amz-Expires=300&X-Amz-Signature=4d642d340d4cac5b5a18cb7228b7a2b9bf78024562f70ed7fbf0896a71e4d0a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-01.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-02-24 18:07:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/035746e8-4e24-47e8-a3ce-edcf6d1b11c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230224%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230224T180718Z&X-Amz-Expires=300&X-Amz-Signature=4d642d340d4cac5b5a18cb7228b7a2b9bf78024562f70ed7fbf0896a71e4d0a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-01.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 129967421 (124M) [application/octet-stream]\n",
      "Saving to: ‘fhvhv_tripdata_2021-01.csv.gz’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 123.95M   410MB/s    in 0.3s    \n",
      "\n",
      "2023-02-24 18:07:18 (410 MB/s) - ‘fhvhv_tripdata_2021-01.csv.gz’ saved [129967421/129967421]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-01.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d600d8e",
   "metadata": {},
   "source": [
    "Unpack .gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673cc2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d fhvhv_tripdata_2021-01.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28396206",
   "metadata": {},
   "source": [
    "Check record count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bf9c776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11908469 fhvhv_tripdata_2021-01.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhvhv_tripdata_2021-01.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e25f84",
   "metadata": {},
   "source": [
    "Set dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2676d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhvhv_tripdata_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21aa9eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime='2021-01-01 00:33:44', dropoff_datetime='2021-01-01 00:49:07', PULocationID='230', DOLocationID='166', SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime='2021-01-01 00:55:19', dropoff_datetime='2021-01-01 01:18:21', PULocationID='152', DOLocationID='167', SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-01-01 00:23:56', dropoff_datetime='2021-01-01 00:38:05', PULocationID='233', DOLocationID='142', SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-01-01 00:42:51', dropoff_datetime='2021-01-01 00:45:50', PULocationID='142', DOLocationID='143', SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime='2021-01-01 00:48:14', dropoff_datetime='2021-01-01 01:08:42', PULocationID='143', DOLocationID='78', SR_Flag=None)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e331d67",
   "metadata": {},
   "source": [
    "Note all of the strings. Unlike Pandas spark does not infer types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccced1a3",
   "metadata": {},
   "source": [
    "Create csv with 1001 rows to determine data types with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af5de649",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1001 fhvhv_tripdata_2021-01.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65303463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e8a9673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num        object\n",
       "dispatching_base_num     object\n",
       "pickup_datetime          object\n",
       "dropoff_datetime         object\n",
       "PULocationID              int64\n",
       "DOLocationID              int64\n",
       "SR_Flag                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda57177",
   "metadata": {},
   "source": [
    "pickup_datetime and dropoff_datetime should be timestamps, otherwise this is good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f673d5",
   "metadata": {},
   "source": [
    "Create spark dataframe from pandas dataframe and show schema. We will use this structure to create the desired schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19a07f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('hvfhs_license_num', StringType(), True), StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('SR_Flag', DoubleType(), True)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas).schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16379c56",
   "metadata": {},
   "source": [
    "Create schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39d16762",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "\ttypes.StructField('hvfhs_license_num', types.StringType(), True), \n",
    "\ttypes.StructField('dispatching_base_num', types.StringType(), True), \n",
    "\ttypes.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "\ttypes.StructField('dropoff_datetime', types.TimestampType(), True), \n",
    "\ttypes.StructField('PULocationID', types.IntegerType(), True), \n",
    "\ttypes.StructField('DOLocationID', types.IntegerType(), True), \n",
    "\ttypes.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1c3fd",
   "metadata": {},
   "source": [
    "Set dataframe with schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bcc3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b825cbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 49, 7), PULocationID=230, DOLocationID=166, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 18, 21), PULocationID=152, DOLocationID=167, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 23, 56), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 38, 5), PULocationID=233, DOLocationID=142, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 42, 51), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 45, 50), PULocationID=142, DOLocationID=143, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 48, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 8, 42), PULocationID=143, DOLocationID=78, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 6, 59), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 43, 1), PULocationID=88, DOLocationID=42, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 50), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 4, 57), PULocationID=42, DOLocationID=151, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 14, 30), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 50, 27), PULocationID=71, DOLocationID=226, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 22, 54), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 30, 20), PULocationID=112, DOLocationID=255, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 40, 12), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 53, 31), PULocationID=255, DOLocationID=232, SR_Flag=None)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d87e4",
   "metadata": {},
   "source": [
    "Now we have 1 large file which is inefficient due to the MPP in Spark. We must repartition. Note that repartition is a lazy command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18210d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hvfhs_license_num: string, dispatching_base_num: string, pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: int, DOLocationID: int, SR_Flag: string]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c75221",
   "metadata": {},
   "source": [
    "Turn the 6 partitions into 24 and write that to parquest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3495c046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a5aef",
   "metadata": {},
   "source": [
    "## Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84866d7",
   "metadata": {},
   "source": [
    "### Actions vs Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f11c71",
   "metadata": {},
   "source": [
    "Transformations - lazy:\n",
    "* selecting columns \n",
    "* filtering\n",
    "* joins\n",
    "* group by\n",
    "\n",
    "Actions - eager:\n",
    "* show, take, head\n",
    "* write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8624191",
   "metadata": {},
   "source": [
    "Create dataframe with parquet files from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a556099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026ccf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de72a637",
   "metadata": {},
   "source": [
    "Note parquet files know and use schemas which is one reason they are smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a6ba5",
   "metadata": {},
   "source": [
    "Selecting specific columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58364d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: int, DOLocationID: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('pickup_datetime','dropoff_datetime','PULocationID','DOLocationID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de2efac",
   "metadata": {},
   "source": [
    "Filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4709404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-18 09:26:34|2021-01-18 09:45:13|         144|         181|\n",
      "|2021-01-18 09:01:10|2021-01-18 09:19:18|         145|         138|\n",
      "|2021-01-18 09:23:03|2021-01-18 09:28:40|         138|          70|\n",
      "|2021-01-18 09:34:22|2021-01-18 09:40:02|         138|         138|\n",
      "|2021-01-18 09:03:11|2021-01-18 09:10:50|          92|         171|\n",
      "|2021-01-18 09:39:57|2021-01-18 09:53:46|          53|         213|\n",
      "|2021-01-18 09:50:14|2021-01-18 10:02:09|          42|         119|\n",
      "|2021-01-18 09:59:00|2021-01-18 10:03:01|         153|         220|\n",
      "|2021-01-18 09:14:15|2021-01-18 09:34:47|           7|         237|\n",
      "|2021-01-18 09:05:00|2021-01-18 09:22:26|         119|         166|\n",
      "|2021-01-18 09:02:52|2021-01-18 09:20:40|         256|          17|\n",
      "|2021-01-18 09:30:05|2021-01-18 09:39:59|         256|         112|\n",
      "|2021-01-18 09:49:57|2021-01-18 10:07:46|         112|         113|\n",
      "|2021-01-18 09:12:32|2021-01-18 09:27:01|         112|          33|\n",
      "|2021-01-18 09:08:30|2021-01-18 09:17:06|         246|          48|\n",
      "|2021-01-18 09:45:07|2021-01-18 09:53:47|          48|         186|\n",
      "|2021-01-18 09:21:22|2021-01-18 09:31:33|          89|          62|\n",
      "|2021-01-18 09:51:05|2021-01-18 10:10:01|         188|          39|\n",
      "|2021-01-18 09:31:47|2021-01-18 09:59:06|         142|          51|\n",
      "|2021-01-18 09:44:28|2021-01-18 10:05:14|          88|         138|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime','dropoff_datetime','PULocationID','DOLocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc6be9",
   "metadata": {},
   "source": [
    "### Functions and UDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceaa28d",
   "metadata": {},
   "source": [
    "Why not just use SQL as it is simpler than the spark syntax above? \n",
    "Spark is more flexible and can allow for user defined functions (udf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01417d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0dbdc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2021-01-18|  2021-01-18|         144|         181|\n",
      "| 2021-01-18|  2021-01-18|         145|         138|\n",
      "| 2021-01-18|  2021-01-18|         138|          70|\n",
      "| 2021-01-18|  2021-01-18|         138|         138|\n",
      "| 2021-01-18|  2021-01-18|          92|         171|\n",
      "| 2021-01-18|  2021-01-18|          53|         213|\n",
      "| 2021-01-18|  2021-01-18|          42|         119|\n",
      "| 2021-01-18|  2021-01-18|         153|         220|\n",
      "| 2021-01-18|  2021-01-18|           7|         237|\n",
      "| 2021-01-18|  2021-01-18|         132|         263|\n",
      "| 2021-01-18|  2021-01-18|         119|         166|\n",
      "| 2021-01-18|  2021-01-18|         256|          17|\n",
      "| 2021-01-18|  2021-01-18|         256|         112|\n",
      "| 2021-01-18|  2021-01-18|         112|         113|\n",
      "| 2021-01-18|  2021-01-18|          33|         265|\n",
      "| 2021-01-18|  2021-01-18|         112|          33|\n",
      "| 2021-01-18|  2021-01-18|         246|          48|\n",
      "| 2021-01-18|  2021-01-18|          48|         186|\n",
      "| 2021-01-18|  2021-01-18|          89|          62|\n",
      "| 2021-01-18|  2021-01-18|         188|          39|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .select('pickup_date','dropoff_date','PULocationID','DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f8631",
   "metadata": {},
   "source": [
    "You can also create custom complex functions that can be stored in a codebase and appropriately tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d803c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac8a99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s/b44'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_stuff('B02884')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc351073",
   "metadata": {},
   "source": [
    "Turn the python function into a udf to be used in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e80b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ef25311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+------------+------------+\n",
      "|base_id|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "|  s/b3d| 2021-01-18|  2021-01-18|         144|         181|\n",
      "|  e/b3b| 2021-01-18|  2021-01-18|         145|         138|\n",
      "|  e/b3b| 2021-01-18|  2021-01-18|         138|          70|\n",
      "|  e/b3b| 2021-01-18|  2021-01-18|         138|         138|\n",
      "|  s/b44| 2021-01-18|  2021-01-18|          92|         171|\n",
      "|  s/b44| 2021-01-18|  2021-01-18|          53|         213|\n",
      "|  e/acc| 2021-01-18|  2021-01-18|          42|         119|\n",
      "|  s/b44| 2021-01-18|  2021-01-18|         153|         220|\n",
      "|  e/acc| 2021-01-18|  2021-01-18|           7|         237|\n",
      "|  e/9ce| 2021-01-18|  2021-01-18|         132|         263|\n",
      "|  e/b38| 2021-01-18|  2021-01-18|         119|         166|\n",
      "|  s/b44| 2021-01-18|  2021-01-18|         256|          17|\n",
      "|  s/b44| 2021-01-18|  2021-01-18|         256|         112|\n",
      "|  s/b44| 2021-01-18|  2021-01-18|         112|         113|\n",
      "|  e/9ce| 2021-01-18|  2021-01-18|          33|         265|\n",
      "|  e/b38| 2021-01-18|  2021-01-18|         112|          33|\n",
      "|  a/b43| 2021-01-18|  2021-01-18|         246|          48|\n",
      "|  a/b43| 2021-01-18|  2021-01-18|          48|         186|\n",
      "|  e/b3b| 2021-01-18|  2021-01-18|          89|          62|\n",
      "|  e/b3b| 2021-01-18|  2021-01-18|         188|          39|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "    .select('base_id','pickup_date','dropoff_date','PULocationID','DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214f569",
   "metadata": {},
   "source": [
    "## Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd57896",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d460419",
   "metadata": {},
   "source": [
    "Make sure you have completed the pre-reqs  https://github.com/TylerJSimpson/data_engineering_zoomcamp/blob/main/week_5/README.MD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022f90f",
   "metadata": {},
   "source": [
    "Load the green and yellow data to dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "becb065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb8fe146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_green.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4bbaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet('data/pq/yellow/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1865df31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486335bb",
   "metadata": {},
   "source": [
    "Combine the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0e4809",
   "metadata": {},
   "source": [
    "Note the differences in schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "012a16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = df_green \\\n",
    "    .withColumnRenamed('lpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('lpep_dropoff_datetime', 'pickup_dropoffe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25712f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'pickup_dropoffe',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'ehail_fee',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'trip_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e949f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = df_yellow \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'pickup_dropoffe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae7ed5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'pickup_dropoffe',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'RatecodeID',\n",
       " 'store_and_fwd_flag',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yellow.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91b9b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = []\n",
    "\n",
    "yellow_columns = set(df_yellow.columns)\n",
    "\n",
    "for col in df_green.columns:\n",
    "    if col in yellow_columns:\n",
    "        common_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d185fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'pickup_datetime',\n",
       " 'pickup_dropoffe',\n",
       " 'store_and_fwd_flag',\n",
       " 'RatecodeID',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'improvement_surcharge',\n",
       " 'total_amount',\n",
       " 'payment_type',\n",
       " 'congestion_surcharge']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b9c8fa",
   "metadata": {},
   "source": [
    "Add service_type column so we know which dataset each record comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17ff5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7565be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_sel = df_green \\\n",
    "    .select(common_columns) \\\n",
    "    .withColumn('service_type', F.lit('green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8eec4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_sel = df_yellow \\\n",
    "    .select(common_columns) \\\n",
    "    .withColumn('service_type', F.lit('yellow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f7baa",
   "metadata": {},
   "source": [
    "Combine the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64b8c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "569c995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=================================================>       (14 + 2) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_trips_data.groupBy('service_type').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713ac43",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35830591",
   "metadata": {},
   "source": [
    "First register the dataframe as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f097cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjsimpson/spark/spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_trips_data.registerTempTable('trips_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32c158",
   "metadata": {},
   "source": [
    "Query the table with Spark SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1a3284b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|service_type|   count|\n",
      "+------------+--------+\n",
      "|       green| 2304517|\n",
      "|      yellow|39649199|\n",
      "+------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT  service_type,\n",
    "        count(service_type) AS count\n",
    "FROM    trips_data \n",
    "GROUP   BY service_type\n",
    ";\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11e901b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Reveneue grouping \n",
    "    PULocationID AS revenue_zone,\n",
    "    date_trunc('month', pickup_datetime) AS revenue_month, \n",
    "    service_type, \n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_montly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_montly_trip_distance\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0d37d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+\n",
      "|revenue_zone|      revenue_month|service_type|revenue_monthly_fare|revenue_monthly_extra|revenue_monthly_mta_tax|revenue_monthly_tip_amount|revenue_monthly_tolls_amount|revenue_monthly_improvement_surcharge|revenue_monthly_total_amount|revenue_monthly_congestion_surcharge|avg_montly_passenger_count|avg_montly_trip_distance|\n",
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+\n",
      "|         250|2020-02-01 00:00:00|       green|  15359.960000000061|               1282.5|                  117.5|                     56.01|           590.3200000000003|                    180.0000000000011|           17598.43999999995|                                11.0|        1.2394957983193278|       4.962810650887575|\n",
      "|         158|2020-02-01 00:00:00|       green|              124.36|                 8.25|                    0.5|                       0.0|                         2.8|                   0.8999999999999999|                      136.81|                                null|                      null|      11.090000000000002|\n",
      "|          15|2020-03-01 00:00:00|       green|  1682.2299999999996|                  5.5|                    6.5|                       0.0|                       79.56|                   19.800000000000026|                     1802.44|                                 0.0|                       1.0|       7.910298507462685|\n",
      "|         229|2020-03-01 00:00:00|       green|   676.3600000000001|                  0.0|                    1.0|                       0.0|          42.839999999999996|                    8.099999999999998|                       728.3|                                 0.0|                       1.0|       7.691111111111111|\n",
      "|         137|2020-10-01 00:00:00|       green|  3480.8299999999995|                  0.0|                    0.0|                     297.0|          250.92000000000007|                   32.400000000000034|          4061.1499999999996|                                null|                      null|       9.184722222222225|\n",
      "|          44|2020-10-01 00:00:00|       green|               146.5|                  3.5|                    2.0|                       5.5|                         0.0|                                  1.2|                       158.7|                                 0.0|                       1.0|                 12.0475|\n",
      "|         152|2020-02-01 00:00:00|       green|            37630.82|              1541.25|                 1398.5|        2836.6600000000035|           538.3700000000003|                    903.8999999999543|           45984.60000000085|                             1336.25|        1.2240055826936498|        2.72640336678537|\n",
      "|         136|2020-03-01 00:00:00|       green|  12226.930000000018|                 60.5|                   89.5|                     32.16|           485.2000000000003|                   163.20000000000047|          13123.939999999977|                                8.25|        1.1637426900584795|      6.4872972972972995|\n",
      "|         119|2020-03-01 00:00:00|       green|             11026.2|                100.5|                  108.5|        40.459999999999994|           525.8000000000003|                    156.0000000000002|           12021.45999999997|                                8.25|        1.0924369747899159|       5.552723880597017|\n",
      "|         153|2020-03-01 00:00:00|       green|  2039.5400000000006|                 15.0|                   30.5|        29.790000000000006|                        33.4|                   34.800000000000026|          2204.7799999999993|                                 0.0|        1.1333333333333333|       4.165042016806725|\n",
      "|          26|2020-03-01 00:00:00|       green|   9467.539999999999|                 52.5|                   52.0|                       0.0|          184.35000000000005|                   122.99999999999919|           9929.640000000001|                                 0.0|        1.1397849462365592|       5.237601918465228|\n",
      "|         243|2019-12-01 00:00:00|       green|               13.99|                  0.0|                    0.0|                       1.0|                         0.0|                                  0.3|                       15.29|                                 0.0|                       1.0|                     0.0|\n",
      "|          28|2020-03-01 00:00:00|       green|   5891.060000000002|                29.25|                   53.0|         80.32000000000001|           195.8400000000001|                    84.29999999999956|           6368.820000000014|                                2.75|        1.2043795620437956|       5.802602739726027|\n",
      "|          45|2020-03-01 00:00:00|       green|             2403.39|                 11.0|                    5.0|                       0.0|                        64.0|                    21.30000000000003|          2506.6399999999994|                                 0.0|                       1.2|       9.125633802816903|\n",
      "|         102|2020-03-01 00:00:00|       green|  2874.7399999999984|                 26.5|                   17.5|                     40.22|                      104.04|                    46.19999999999992|           3135.650000000001|                                 5.5|        1.1481481481481481|       4.857922077922078|\n",
      "|          48|2020-10-01 00:00:00|       green|  1504.4299999999998|                  0.0|                    0.0|                     115.5|           75.72999999999999|                   12.600000000000003|          1708.2600000000007|                                null|                      null|       9.061428571428571|\n",
      "|          20|2020-01-01 00:00:00|       green|            11375.42|                681.0|                  131.0|         90.61999999999999|           479.8600000000003|                   147.29999999999987|          12923.199999999997|                                11.0|        1.2297872340425533|       4.872311926605508|\n",
      "|         130|2020-03-01 00:00:00|       green|   60166.09999999997|               1436.5|                 1759.0|        4972.6999999999925|           731.1700000000004|                   1234.1999999999043|           70458.47000000314|                               74.25|        1.1157574079202437|      3.8739044205495867|\n",
      "|          18|2020-03-01 00:00:00|       green|   9502.130000000005|                 69.5|                  100.0|                     78.06|          414.14000000000027|                   136.19999999999945|          10401.979999999987|                                 5.5|        1.1727272727272726|       5.481708860759492|\n",
      "|         265|2020-10-01 00:00:00|       green|   5726.509999999998|                16.25|                   33.0|                    329.22|          213.68000000000006|                   38.700000000000045|           6359.310000000004|                                2.75|         1.178082191780822|      12.571085271317834|\n",
      "+------------+-------------------+------------+--------------------+---------------------+-----------------------+--------------------------+----------------------------+-------------------------------------+----------------------------+------------------------------------+--------------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499fbf4",
   "metadata": {},
   "source": [
    "Saving outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fedff852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet('data/report/revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b32e96",
   "metadata": {},
   "source": [
    "This creates over 200 files, you can specify 1 (must overwrite if using the same path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dbb047c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.coalesce(1).write.parquet('data/report/revenue', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275cef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
